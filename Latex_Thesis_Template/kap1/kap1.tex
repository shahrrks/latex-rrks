\chapter{Introduction}

Over the past decade, the proliferation of smart home and Internet of Things (IoT) devices has considerably enhanced the quality of our daily lives. However, these technological advancements come at a hidden cost. With the advancements in complex machine learning algorithms, there have been growing concerns about the sensitive data collected by big tech companies and the potential misuse of this information.\\
Speech signals encapsulate a wealth of information and can reveal a multitude of characteristics such as accent, pitch, speed, gender, health status, and the emotional state of the speaker. By analyzing the content of speech like tone, bass, timbre, articulation, rhythm, stress patterns, and phonetic nuances over time, one can discern not only the overt message being conveyed but also subtle cues that hint at the speaker's background, upbringing, and current state of mind. These cues, when interpreted correctly, can provide insights into shopping preferences, linguistic habits, social interactions, and behavioral patterns. Using advanced machine learning methodologies, a comprehensive profile of an individual user can be derived, particularly when distinct speaker identification is achievable.
In reaction to growing concerns, a myriad of legal frameworks and standards have been instituted globally. Prominent among these are the European Union’s General Data Protection Regulation (GDPR) \cite{gdpr}, the California Consumer Privacy Act (CCPA) \cite{ccpa}, and Brazil’s General Personal Data Protection Law (LGPD) \cite{lgpd}. These regulations mandate corporations to integrate \textit{privacy-by-design} principles during the development of signal processing systems. Consequently,  these have amplified the urgency and significance of research in the arena of privacy-preserving signal processing.\\



\textit{Utility} represents the enhanced capabilities and service quality offered by modern speech command services provided by corporations. However, the pursuit of this \textit{utility} inherently involves a trade-off: the risk of data exposure, thereby compromising \textit{privacy}. \textit{Utility} emphasizes the functionality and efficiency of a service, aiming to maximize user benefit and experience, while \textit{privacy} prioritizes the protection of personal information to ensure that users' data remains confidential and secure. While \textit{utility} seeks optimization through data analysis, \textit{privacy} cautions against potential overreach and misuse. Balancing \textit{utility} and \textit{privacy} is a challenge, as it aims to maximize service efficiency while safeguarding user data.\\

The privacy enhancement approach in this project incorporates the use of a feature extraction model, transmitting only the essential features from the raw data to the server, thereby minimizing mutual information. This method is inspired by the paper \cite{nelus}, aiming to optimize accuracy in gender discrimination (\textit{utility}) while ensuring the results for speaker identification remain non-distinctive to maintain \textit{privacy}. This approach draws inspiration from the concept of the \textit{Variational Information Bottleneck} (VIB) \cite{alemi2017deep}, which is motivated by the \textit{Information Bottleneck} (IB) principle \cite{tishby2000information}. This principle aims to retain only the most relevant information for a task, thereby reducing the risk of exposing unnecessary data. The VIB method incorporates elements of the \textit{variational autoencoder}, a type of neural network(NN) that can generate new, similar data based on the training set. This technique encodes compact data representations and employs a \textit{re-parametrization} method \cite{kingma2013auto}, introducing variability and allowing for stochastic sampling during backpropagation. This helps optimize the balance between \textit{utility} and \textit{privacy} by ensuring that the model does not overfit to sensitive information.\\


In this project, we deploy a deep neural network(DNN)-based, privacy-aware feature extraction technique for gender recognition(GR) and speaker identification(SI), as detailed in the referenced paper \cite{nelus}. The primary goal is to balance the trade-off between GR and SI, thereby mitigating potential data exposure risks by minimizing the amount of data transferred over the channel. Our investigation into this scenario aims to enhance the classifier's GR capabilities while simultaneously restricting access to precise speaker identity information.

The aim of this work is to examine the effectiveness of the trainable acoustic frontend, Per Channel Energy Normalization (PCEN), in GR vs SI tasks. To evaluate this, we compared the performance of Per Channel Energy Normalization(PCEN) with that of Log Mel Band Energy (LMBE) as a feature extractor. We evaluated the performance of PCEN with both trainable and non-trainable parameters. We utilized the \textit{Librispeech} dataset for our experiment and extracted high-level features by training the GR trust model. Next, applying the VIB principle, we established a probabilistic mapping between the input data and a compact latent space through the \textit{re-parametrization trick}, as discussed in \cref{sec:rpTrick}. By leveraging the VIB principle and gradually increasing the budget scaling factor \( \beta \), our goal is to identify a \( \beta \) at which the features compress in such a way that GR remains achievable, but SI becomes challenging. Furthermore, we investigated the accuracy of the SI by training the high-level feature extractor, referred to as the Trust model, using the \textit{Sonyc UST} dataset.


Before transmitting information to the server side, a scheme can be applied at the node level that employs deep neural network (DNN)-based feature extraction. We utilize a privacy-centric variational information feature extraction technique that deliberately produces lossy results, anchoring on Mutual Information (MI) minimization. Our analysis focuses on its impact on the delicate balance between GR accuracy (\textit{utility}) and SI (\textit{privacy}). Striking a balance between these two elements is crucial; optimizing one often compromises the other. We examine the loss function and the budget scaling factor \( \beta  \), which influences the trade-off between \textit{utility} and \textit{privacy}, for our proposed model. Experimental results have demonstrated that our method substantially mitigates the associated privacy risks without causing significant degradation in \textit{utility}. Impressively, these outcomes are also consistent with speech sources not previously observed. In the context of wireless acoustic sensor networks (WASNs), implementing node-level feature extraction is especially beneficial as it offers the potential to decrease bandwidth consumption, distribute computational load across the network, and hence enhance \textit{privacy} by incorporating aggregation techniques.

\pagebreak

The structure of the thesis is organized as follows:

\begin{itemize}
    \item \textbf{Chapter 2: Feature Extraction} provides an overview of various techniques, emphasizing the detailed discussion on Log Mel Band Energy (LMBE) and Per Channel Energy Normalization (PCEN).
    
    \item \textbf{Chapter 3: Fundamentals of Deep Learning Networks} delves into the core concepts of DNN, covering topics such as activation functions, optimization methods, Convolutional Neural Networks (CNN), and the training processes of DNNs.
    
    \item \textbf{Chapter 4: Privacy-preserving Feature Extraction} explores methodologies and principles for preserving privacy in feature extraction, including discussions on the Variational Autoencoders (VAE), Variational Information Bottleneck(VIB) principle and the reparametrization trick.
    
    \item \textbf{Chapter 5: Experimental Setup and Results} details the experimental framework for both the \textit{Librispeech} and \textit{SONYC UST} datasets and presents the findings obtained from the experiments.
\end{itemize}

